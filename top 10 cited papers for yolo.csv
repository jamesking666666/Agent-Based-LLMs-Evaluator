"ID","Tittle","Citations","Statistical reference date","Authors","Journal","Year","Abstract","Keywords","Author Information"
"1","Apple detection during different growth stages in orchards using the improved YOLO-V3 model","792","31/7/2025","Tian, YN (Tian, Yunong) ; Yang, GD (Yang, Guodong); Wang, Z (Wang, Zhe) ; Wang, H (Wang, Hao) ; Li, E (Li, En) ; Liang, ZZ (Liang, Zize) ","
COMPUTERS AND ELECTRONICS IN AGRICULTURE","2019-2","Real-time detection of apples in orchards is one of the most important methods for judging growth stages of apples and estimating yield. The size, colour, cluster density, and other growth characteristics of apples change as they grow. Traditional detection methods can only detect apples during a particular growth stage, but these methods cannot be adapted to different growth stages using the same model. We propose an improved YOLO-V3 model for detecting apples during different growth stages in orchards with fluctuating illumination, complex backgrounds, overlapping apples, and branches and leaves. Images of young apples, expanding apples, and ripe apples are initially collected. These images are subsequently augmented using rotation transformation, colour balance transformation, brightness transformation, and blur processing. The augmented images are used to create training sets. The DenseNet method is used to process feature layers with low resolution in the YOLO-V3 network. This effectively enhances feature propagation, promotes feature reuse, and improves network performance. After training the model, the performance of the trained model is tested on a test dataset. The test results show that the proposed YOLOV3-dense model is superior to the original YOLO-V3 model and the Faster R-CNN with VGG16 net model, which is the state-of-art fruit detection model. The average detection time of the model is 0.304 s per frame at 3000 x 3000 resolution, which can provide real-time detection of apples in orchards. Moreover, the YOLOV3-dense model can effectively provide apple detection under overlapping apples and occlusion conditions, and can be applied in the actual environment of orchards.","Apple images acquisitionImage augmentationDeep learningYOLOV3-denseReal-time detection
Keywords PlusVISIONFRUITS","Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China"
"10","An improved fire detection approach based on YOLO-v8 for smart cities","275","31/7/2025","Talaat, FM (Talaat, Fatma M.) ; ZainEldin, H (ZainEldin, Hanaa)","NEURAL COMPUTING & APPLICATIONSarrow_drop_down","2023-7","Fires in smart cities can have devastating consequences, causing damage to property, and endangering the lives of citizens. Traditional fire detection methods have limitations in terms of accuracy and speed, making it challenging to detect fires in real time. This paper proposes an improved fire detection approach for smart cities based on the YOLOv8 algorithm, called the smart fire detection system (SFDS), which leverages the strengths of deep learning to detect fire-specific features in real time. The SFDS approach has the potential to improve the accuracy of fire detection, reduce false alarms, and be cost-effective compared to traditional fire detection methods. It can also be extended to detect other objects of interest in smart cities, such as gas leaks or flooding. The proposed framework for a smart city consists of four primary layers: (i) Application layer, (ii) Fog layer, (iii) Cloud layer, and (iv) IoT layer. The proposed algorithm utilizes Fog and Cloud computing, along with the IoT layer, to collect and process data in real time, enabling faster response times and reducing the risk of damage to property and human life. The SFDS achieved state-of-the-art performance in terms of both precision and recall, with a high precision rate of 97.1% for all classes. The proposed approach has several potential applications, including fire safety management in public areas, forest fire monitoring, and intelligent security systems.","Smart cityFire detectionYOLOv8Deep learning","Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt"
"2","Object detection using YOLO: challenges, architectural successors, datasets and applications","537","31/7/2025","Diwan, T (Diwan, Tausif); Anirudh, G (Anirudh, G[2] ; Tembhurne, J (Tembhurne, Jitendra, V)","MULTIMEDIA TOOLS AND APPLICATIONS","2023-3","Object detection is one of the predominant and challenging problems in computer vision. Over the decade, with the expeditious evolution of deep learning, researchers have extensively experimented and contributed in the performance enhancement of object detection and related tasks such as object classification, localization, and segmentation using underlying deep models. Broadly, object detectors are classified into two categories viz. two stage and single stage object detectors. Two stage detectors mainly focus on selective region proposals strategy via complex architecture; however, single stage detectors focus on all the spatial region proposals for the possible detection of objects via relatively simpler architecture in one shot. Performance of any object detector is evaluated through detection accuracy and inference time. Generally, the detection accuracy of two stage detectors outperforms single stage object detectors. However, the inference time of single stage detectors is better compared to its counterparts. Moreover, with the advent of YOLO (You Only Look Once) and its architectural successors, the detection accuracy is improving significantly and sometime it is better than two stage detectors. YOLOs are adopted in various applications majorly due to their faster inferences rather than considering detection accuracy. As an example, detection accuracies are 63.4 and 70 for YOLO and Fast-RCNN respectively, however, inference time is around 300 times faster in case of YOLO. In this paper, we present a comprehensive review of single stage object detectors specially YOLOs, regression formulation, their architecture advancements, and performance statistics. Moreover, we summarize the comparative illustration between two stage and single stage object detectors, among different versions of YOLOs, applications based on two stage detectors, and different versions of YOLOs along with the future research directions.","Object detectionConvolutional neural networksYOLODeep learningComputer vision","Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India"
"3","YOLO-v1 to YOLO-v8, the Rise of YOLO and Its Complementary Nature toward Digital Manufacturing and Industrial Defect Detection","444","31/7/2025","Hussain, M (Hussain, Muhammad)","
MACHINES","2023-7","Since its inception in 2015, the YOLO (You Only Look Once) variant of object detectors has rapidly grown, with the latest release of YOLO-v8 in January 2023. YOLO variants are underpinned by the principle of real-time and high-classification performance, based on limited but efficient computational parameters. This principle has been found within the DNA of all YOLO variants with increasing intensity, as the variants evolve addressing the requirements of automated quality inspection within the industrial surface defect detection domain, such as the need for fast detection, high accuracy, and deployment onto constrained edge devices. This paper is the first to provide an in-depth review of the YOLO evolution from the original YOLO to the recent release (YOLO-v8) from the perspective of industrial manufacturing. The review explores the key architectural advancements proposed at each iteration, followed by examples of industrial deployment for surface defect detection endorsing its compatibility with industrial requirements.","industrial defect detectionobject detectionsmart manufacturingquality inspection","Univ Huddersfield, Sch Comp & Engn, Dept Comp Sci, Queensgate, Huddersfield HD1 3DH, England"
"4","Using channel pruning-based YOLO v4 deep learning algorithm for the real-time and accurate detection of apple flowers in natural environments","374","31/7/2025","Wu, DH (Wu, Dihua) ; Lv, SC (Lv, Shuaichao) ; Jiang, M (Jiang, Mei); Song, HB (Song, Huaibo)","COMPUTERS AND ELECTRONICS IN AGRICULTURE","2021-1","Achieving the rapid and accurate detection of apple flowers in natural environments is essential for yield estimation and the development of an automatic flower thinner. A real-time apple flower detection method using the channel pruned YOLO v4 deep learning algorithm was proposed. First, the YOLO v4 model under the CSPDarknet53 framework was built, and then, to simplify the apple flower detection model and ensure the efficiency of the model, the channel pruning algorithm was used to prune the model. Finally, a total of 2230 manually labeled apple flower images (including three varieties of Fuji, Red Love, and Gala) were used to fine-tune the model to achieve the fast and accurate detection of apple flowers. The test results showed that the number of parameters of the apple flower detection model after pruning was reduced by 96.74%, the model size was reduced by 231.51 MB, the inference time was decreased by 39.47%, and the mAP was 97.31%, which was only 0.24% lower than the model before pruning. To verify the effectiveness of the proposed method, five different deep learning algorithms including the Faster R-CNN, Tiny-YOLO v2, YOLO v3, SSD 300 and EfficientDet-D0 were compared. The comparative results showed that the mAP of the apple flower detection using the proposed method was 97.31%; the detection speed was 72.33f/s; the model size was 12.46 MB; the mAP was 12.21%, 15.56%, 14.19%, 5.67% and 7.79% higher than the other five algorithms, respectively; and the detection speed could meet the real-time requirements. Furthermore, the detection performance of apple flowers under different species of apple trees and illumination conditions was discussed. The results indicated that the proposed method had strong robustness to the changes of fruit tree varieties and illumination directions. The results showed that it was feasible to apply the proposed method for the real-time and accurate detection of apple flowers. The research could provide technical references for orchard yield estimation and the development of apple flower thinning robots.","Apple flowerYOLO v4Channel pruning algorithmReal-time detectionNatural environments","Northwest A&F Univ, Coll Mech & Elect Engn, 22 Xinong Rd, Yangling 712100, Shaanxi, Peoples R China"
"5","Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system","319","31/7/2025","Al-masni, MA (Al-masni, Mohammed A.)  ; Al-antari, MA (Al-antari, Mugahed A.); Park, JM (Park, Jeong-Min) ; Gi, G (Gi, Geon); Kim, TY (Kim, Tae-Yeon) ; Rivera, P (Rivera, Patricio) ; Valarezo, E (Valarezo, Edwin) ; Choi, MT (Choi, Mun-Taek) ; Han, SM (Han, Seung-Moo) ; Kim, TS (Kim, Tae-Seong)","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINEarrow_drop_down","2018-4","Background and objective: Automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. In this paper, we propose a novel Computer-Aided Diagnosis (CAD) system based on one of the regional deep learning techniques, a ROI-based Convolutional Neural Network (CNN) which is called You Only Look Once (YOLO). Although most previous studies only deal with classification of masses, our proposed YOLO-based CAD system can handle detection and classification simultaneously in one framework.

Methods: The proposed CAD system contains four main stages: preprocessing of mammograms, feature extraction utilizing deep convolutional networks, mass detection with confidence, and finally mass classification using Fully Connected Neural Networks (FC-NNs). In this study, we utilized original 600 mammograms from Digital Database for Screening Mammography (DDSM) and their augmented mammograms of 2,400 with the information of the masses and their types in training and testing our CAD. The trained YOLO-based CAD system detects the masses and then classifies their types into benign or malignant.

Results: Our results with five-fold cross validation tests show that the proposed CAD system detects the mass location with an overall accuracy of 99.7%. The system also distinguishes between benign and malignant lesions with an overall accuracy of 97%.

Conclusions: Our proposed system even works on some challenging breast cancer cases where the masses exist over the pectoral muscles or dense regions. (C) 2018 Elsevier B.V. All rights reserved.","Breast cancerMass detection and classificationComputer Aided DiagnosisDeep learningYou Only Look Once (YOLO)","Kyung Hee Univ, Coll Elect & Informat, Dept Biomed Engn, Yongin, South Korea"
"6","Tomato Diseases and Pests Detection Based on Improved Yolo V3 Convolutional Neural Network","317","31/7/2025","Liu, J (Liu, Jun) ; Wang, XW (Wang, Xuewei)","FRONTIERS IN PLANT SCIENCE","2020-6","Tomato is affected by various diseases and pests during its growth process. If the control is not timely, it will lead to yield reduction or even crop failure. How to control the diseases and pests effectively and help the vegetable farmers to improve the yield of tomato is very important, and the most important thing is to accurately identify the diseases and insect pests. Compared with the traditional pattern recognition method, the diseases and pests recognition method based on deep learning can directly input the original image. Instead of the tedious steps such as image preprocessing, feature extraction and feature classification in the traditional method, the end-to-end structure is adopted to simplify the recognition process and solve the problem that the feature extractor designed manually is difficult to obtain the feature expression closest to the natural attribute of the object. Based on the application of deep learning object detection, not only can save time and effort, but also can achieve real-time judgment, greatly reduce the huge loss caused by diseases and pests, which has important research value and significance. Based on the latest research results of detection theory based on deep learning object detection and the characteristics of tomato diseases and pests images, this study will build the dataset of tomato diseases and pests under the real natural environment, optimize the feature layer of Yolo V3 model by using image pyramid to achieve multi-scale feature detection, improve the detection accuracy and speed of Yolo V3 model, and detect the location and category of diseases and pests of tomato accurately and quickly. Through the above research, the key technology of tomato pest image recognition in natural environment is broken through, which provides reference for intelligent recognition and engineering application of plant diseases and pests detection.","deep learningK-meansmultiscale trainingsmall objectobject detection","Weifang Univ Sci & Technol, Facil Hort Lab Univ Shandong, Weifang, Peoples R China"
"7","Pavement distress detection and classification based on YOLO network","305","31/7/2025","
Du, YC (Du, Yuchuan) ; Pan, N (Pan, Ning) ; Xu, ZH (Xu, Zihao) ; Deng, FW (Deng, Fuwen) ; Shen, Y (Shen, Yu) ; Kang, H (Kang, Hua) ","INTERNATIONAL JOURNAL OF PAVEMENT ENGINEERING","2021-11","The detection and classification of pavement distress (PD) play a critical role in pavement maintenance and rehabilitation. Research on PD automation detection and measurement has been actively conducted. However, types of PD are more necessary for road managers to take effective actions. Also, lack of a unified PD dataset leads to absence of a benchmark on various methods. This study makes three contributions to address these issues. Firstly, a large-scale PD dataset is prepared. This dataset is composed of 45,788 images captured with a high-resolution industrial camera installed on vehicles, in a variety of weather and illuminance conditions. Each image is annotated with bounding box representing location and type of distress. Secondly, a deep learning-based object detection framework, the YOLO network, is adopted to predict possible distress location and category. Comprehensive detection accuracy reaches 73.64%. The processing speed reaches 0.0347s/pic, as 9 times faster than Faster R-CNN and only 70% of SSD. Finally, the applicability of model under various illumination conditions is also explored. The results reveal that the method significantly outperforms with appropriate illumination. We conclude that the proposed YOLO-based approach is able to detect PD with high accuracy, which requires no manual feature extraction and calculation during detecting.","Pavement distressobject detectionimage classificationYOLO network","Tongji Univ, Minist Educ, Key Lab Rd & Traff Engn, Shanghai, Peoples R China"
"8","YOLO-Tomato: A Robust Algorithm for Tomato Detection Based on YOLOv3","301","31/7/2025","Liu, GX (Liu, Guoxu) ; Nouaze, JC (Nouaze, Joseph Christian) ; Mbouembe, PLT (Mbouembe, Philippe Lyonel Touko) ; Kim, JH (Kim, Jae Ho)","SENSOR","2020-4","Automatic fruit detection is a very important benefit of harvesting robots. However, complicated environment conditions, such as illumination variation, branch, and leaf occlusion as well as tomato overlap, have made fruit detection very challenging. In this study, an improved tomato detection model called YOLO-Tomato is proposed for dealing with these problems, based on YOLOv3. A dense architecture is incorporated into YOLOv3 to facilitate the reuse of features and help to learn a more compact and accurate model. Moreover, the model replaces the traditional rectangular bounding box (R-Bbox) with a circular bounding box (C-Bbox) for tomato localization. The new bounding boxes can then match the tomatoes more precisely, and thus improve the Intersection-over-Union (IoU) calculation for the Non-Maximum Suppression (NMS). They also reduce prediction coordinates. An ablation study demonstrated the efficacy of these modifications. The YOLO-Tomatowas compared to several state-of-the-art detection methods and it had the best detection performance.","tomato detectionharvesting robotsdense architecturedeep learning","Weifang Univ Sci & Technol, Comp Software Inst, Shouguang 262700, Peoples R China"
"9","A High-Throughput and Power-Efficient FPGA Implementation of YOLO CNN for Object Detection","297","31/7/2025","Nguyen, DT (Duy Thanh Nguyen) ; Nguyen, TN (Tuan Nghia Nguyen) ; Kim, H (Kim, Hyun) , [3] ; Lee, HJ (Lee, Hyuk-Jae)","IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMSarrow_drop_down","2019-8","Convolutional neural networks (CNNs) require numerous computations and external memory accesses. Frequent accesses to off-chip memory cause slow processing and large power dissipation. For real-time object detection with high throughput and power efficiency, this paper presents a Tera-OPS streaming hardware accelerator implementing a you-only-look-once (YOLO) CNN. The parameters of the YOLO CNN are retrained and quantized with the PASCAL VOC data set using binary weight and flexible low-bit activation. The binary weight enables storing the entire network model in block RAMs of a field-programmable gate array (FPGA) to reduce off-chip accesses aggressively and, thereby, achieve significant performance enhancement. In the proposed design, all convolutional layers are fully pipelined for enhanced hardware utilization. The input image is delivered to the accelerator line-by-line. Similarly, the output from the previous layer is transmitted to the next layer line-by-line. The intermediate data are fully reused across layers, thereby eliminating external memory accesses. The decreased dynamic random access memory (DRAM) accesses reduce DRAM power consumption. Furthermore, as the convolutional layers are fully parameterized, it is easy to scale up the network. In this streaming design, each convolution layer is mapped to a dedicated hardware block. Therefore, it outperforms the "" one-size-fits-all"" designs in both performance and power efficiency. This CNN implemented using VC707 FPGA achieves a throughput of 1.877 tera operations per second (TOPS) at 200 MHz with batch processing while consuming 18.29 W of on-chip power, which shows the best power efficiency compared with the previous research. As for object detection accuracy, it achieves a mean average precision (mAP) of 64.16% for the PASCAL VOC 2007 data set that is only 2.63% lower than the mAP of the same YOLO network with full precision.","Binary weightlow-precision quantizationobject detectionstreaming architectureyou-only-look-once (YOLO)","Seoul Natl Univ Sci & Technol, Dept Elect & Informat Engn, Seoul 01811, South Korea"
