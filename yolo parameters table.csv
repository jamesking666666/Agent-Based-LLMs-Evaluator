"ID","version","Release time","Author's Name","Paper publishing unit","Paper and Journal Name","Main structure of the model","Key performance data indicators"
"1","YOLOv1","2015","Joseph Redmon、Ali Farhadi
","University of Washington","《You Only Look Once: Unified, Real-Time Object Detection》, CVPR
","Divide the input image into S × S grids, and predict B bounding boxes and 1 category probability distribution for each grid cell. Composed of a single convolutional neural network, the backbone network is Darknet, which includes 24 convolutional layers and 2 fully connected layers.","The mAP on the PASCAL VOC 2007 dataset is 63.4%, achieving end-to-end, single-stage real-time object detection with fast inference speed of up to 45 frames per second. Its simplified detection process lays the foundation for future research"
"2","YOLOv2","2016","Joseph Redmon、Ali Farhadi
","University of Washington","《YOLO9000: Better, Faster, Stronger》, CVPR
","Adopting Darknet-19 backbone network and introducing anchor box mechanism, anchor box size is generated through dimensional clustering, and fine-grained features are fused using Passthrough layer. The fully convolutional network structure combines classification and detection tasks during the training process.","On the PASCAL VOC 2007 dataset, the mAP can reach 78.6% and can detect 9000 types of objects. On the COCO dataset, the mAP50 index is 44.0%. Improved detection accuracy, expanded detection categories, and enhanced model generalization ability while maintaining a certain speed"
"3","YOLOv3","2018","Joseph Redmon、Ali Farhadi
","University of Washington","《YOLOv3: An Incremental Improvement》, ArXiv
","Using Darknet-53 backbone network and multi-scale training, output feature maps at three scales, and fuse features through FPN network feature pyramid. The network deepens and widens, with more convolutional layers.","On the COCO dataset, the inference time reached 28.2 mAP in 22 milliseconds and 57.9 AP50 in 51 milliseconds. Further improved the detection capability for small targets, achieving a good balance between detection accuracy and speed"
"4","YOLOv4","2020","Alexey Bochkovskiy、Chien-Yao Wang、Hong-Yuan Mark Liao","Institute of Information Science, Academia Sinica, Taiwan","《YOLOv4: Optimal Speed and Accuracy of Object Detection》, ArXiv
","The backbone network is CSPDarknet53, which introduces Mosaic data augmentation, uses SPP module to increase receptive field, uses PANnet for feature fusion, as well as CBN, SAM and other technologies. Optimize the network architecture to accommodate different hardware accelerations.","On the COCO dataset, the mAP is 43.5%, demonstrating excellent overall performance. It can run efficiently on different hardware platforms, balancing speed and accuracy"
"5","YOLOv5","2020","Glenn Jocher","Ultralytics","None","Adopting grayscale filling to unify input size and introducing Focus structure, the network structure includes backbone network, neck network, and head network, with different scale versions such as YOLOv5s, YOLOv5m, YOLOv5l, YOLOv5x, etc. The network structure design is flexible and can be adjusted according to needs.","Has good performance on the COCO dataset, with fast inference speed. For example, the YOLOv5s model has a good balance between speed and accuracy, and is suitable for various practical scenarios. It is widely used in the industrial sector"
"6","YOLOv6
","2022","Meituan Visual Intelligence Department","Meituan","None","Specially designed for industrial applications, using anchor free detectors, Backbone and Neck have been redesigned to improve the efficiency of hardware such as GPU, including backbone network, neck, and head. Adopting RepVGG style Backbone and efficient Neck structure.","Suitable for scenarios such as Meituan automatic delivery robots, it performs well in industrial target detection, with fast inference speed on GPUs and high detection accuracy on industrial datasets, meeting the high real-time requirements of industrial applications"
"7","YOLOv7
","2022","Alexey Bochkovskiy
","None","《YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors》, ArXiv
","Proposed optimization of model structure reparameterization and dynamic label assignment problems, reducing parameter and computational complexity, and increasing support for additional tasks such as pose estimation on COCO keypoint datasets. There are innovations in network structure and training strategies.","Further improve detection performance, reduce computational complexity, while maintaining high detection accuracy, reduce the model's demand for computing resources, and enable multitasking detection such as pose estimation"
"8","YOLOv8","2023","Ultralytics","None","None","Anchor free design with faster NMS process, providing models of different sizes (such as YOLOv8-N, YOLOv8-S, etc.) to meet different performance and accuracy requirements, including new backbone and head designs. Improved C2f module and other structures have been adopted.","Has demonstrated excellent performance, flexibility, and efficiency in various visual tasks, with outstanding performance on multiple datasets such as COCO, and outstanding accuracy and speed in tasks such as detection, segmentation, and pose estimation"
"9","YOLOv9
","2024","Alexey Bochkovskiy","None","None","The concept of programmable gradient information (PGI) was proposed, and a general efficient layer aggregation network (GELAN) based on gradient path planning was designed. Innovate the utilization of gradient information and network aggregation structure.","No specific performance indicators were mentioned, but theoretically, the introduction of new methods has improved performance. By optimizing the utilization of gradients and improving network structure, it is expected to enhance detection accuracy and efficiency"
"10","YOLOv10","2024","Tsinghua University","Tsinghua University","None","Introducing end-to-end (End to End head) and eliminating non maximum suppression (NMS) requirements, there are different versions such as YOLOv10-N and YOLOv10-S. Redesigned the structure of the detection head.","The progress of real-time object detection has been achieved, with faster speed and significant improvement in speed, while maintaining high detection accuracy and simplifying the detection process"
"11","YOLOv11","2024","Ultralytics
","None","None","Introducing end-to-end (End to End head) and eliminating non maximum suppression (NMS) requirements, there are different versions such as YOLOv10-N and YOLOv10-S. Redesigned the structure of the detection head.","It can provide advanced performance in multiple tasks such as object detection, segmentation, attitude estimation, tracking and classification, and has multi task processing capability. Its performance is better than some old versions"
"12","YOLOv12","2025","Tian Yunjie","None","《YOLOv12: Towards Attention-Centric Vision Transformer for Object Detection》， ArXiv
","Introduce an attention centered architecture that includes a region attention module (A ²) and a residual efficient layer aggregation network (R-ELAN). Remove positional encoding, adjust MLP ratio, reduce block stacking in the final stage of backbone network, and optimize memory access using FlashAttention. There are five different sized versions of YOLOv12-N, YOLOv12-S, YOLOv12-M, YOLOv12-L, and YOLOv12-X","The inference latency of YOLOv12-N on T4 GPU is 1.64 milliseconds, and the mAP reaches 40.6%. YOLOv12-S achieved 48.0 mAP with 21.4G FLOPs and 9.3M parameters, with a latency of 2.61 milliseconds per image. YOLOv12-M achieved 52.5 mAP with 67.5G FLOPs and 20.2M parameters, with an inference speed of 4.86 milliseconds per image."
"13","YOLOv13","2025","Tsinghua University","None","《YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception》, ArXiv
","Propose an adaptive visual perception mechanism for hypergraph enhancement, mining potential global high-order correlations through hypergraph modeling, and achieving multi-scale feature fusion and enhancement based on correlation guidance. Adopting the Full Process Aggregation and Allocation paradigm (FullPAD) to distribute the enhanced features throughout the network, promoting information flow. Designed a series of lightweight feature extraction modules based on depthwise separable convolution. Model versions with different scales of N/S/L/X","A large number of experiments were conducted on the MS COCO dataset, and quantitative and qualitative results showed that the method achieved leading performance with lower computational complexity. The specific indicators are that the detection accuracy in complex scenarios has significantly improved compared to similar models. While maintaining high frame rates, key indicators such as mAP have reached new heights. Models of different scales have excellent performance in speed and accuracy. For example, small models can quickly and accurately detect targets on low computing devices, while large models perform outstandingly in scenarios that pursue ultimate accuracy"
